{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalMovieRecommenderSystem.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "pX7fwp0Y3RlL",
        "xbOBrIWM8rEJ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX7fwp0Y3RlL"
      },
      "source": [
        "#Importing The Libraries\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhEX9Sop3eaf"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZuPRsDL3ypp"
      },
      "source": [
        "#Training set and the Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9QwKf4H31Cr"
      },
      "source": [
        "training_set_1 = pd.read_csv('/u50_1.base', delimiter = ',')\n",
        "training_set_1 = np.array(training_set_1, dtype = 'int')\n",
        "test_set_1 = pd.read_csv('/u50_1.test', delimiter = ',')\n",
        "test_set_1 = np.array(test_set_1, dtype = 'int')\n",
        "\n",
        "training_set_2 = pd.read_csv('/u50_2.base', delimiter = ',')\n",
        "training_set_2 = np.array(training_set_1, dtype = 'int')\n",
        "test_set_2 = pd.read_csv('/u50_2.test', delimiter = ',')\n",
        "test_set_2 = np.array(test_set_1, dtype = 'int')\n",
        "\n",
        "training_set_3 = pd.read_csv('/u50_3.base', delimiter = ',')\n",
        "training_set_3 = np.array(training_set_1, dtype = 'int')\n",
        "test_set_3 = pd.read_csv('/u50_3.test', delimiter = ',')\n",
        "test_set_3 = np.array(test_set_1, dtype = 'int')\n",
        "\n",
        "training_set_4 = pd.read_csv('/u50_4.base', delimiter = ',')\n",
        "training_set_4 = np.array(training_set_1, dtype = 'int')\n",
        "test_set_4 = pd.read_csv('/u50_4.test', delimiter = ',')\n",
        "test_set_4 = np.array(test_set_1, dtype = 'int')\n",
        "\n",
        "training_set_5 = pd.read_csv('/u50_5.base', delimiter = ',')\n",
        "training_set_5 = np.array(training_set_1, dtype = 'int')\n",
        "test_set_5 = pd.read_csv('/u50_5.test', delimiter = ',')\n",
        "test_set_5 = np.array(test_set_1, dtype = 'int')\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G74eQaq7WtV0"
      },
      "source": [
        "# Getting the number of users and movies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KDhfPZ9Ww8W"
      },
      "source": [
        "user_count_training_set = int(max(training_set_1[:, 0]))\n",
        "user_count_test_set = int(max(test_set_1[:, 0]))\n",
        "user_count = int(max(user_count_test_set, user_count_training_set))\n",
        "\n",
        "movies_count_training_set = int(max(training_set_1[:, 1]))\n",
        "movies_count_test_set = int(max(test_set_1[:, 1]))\n",
        "movies_count = int(max(movies_count_test_set, movies_count_training_set))\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyRvm4ngD5jG"
      },
      "source": [
        "# Converting the data into an array with users in rows and movies in columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asZD2isMD9cX"
      },
      "source": [
        "def modify(data):\n",
        "  listoflist = []\n",
        "  for ui in range(1, user_count+1):\n",
        "    mi =data[:, 1][data[:, 0]==ui]\n",
        "    ri =data[:, 2][data[:, 0]==ui]\n",
        "    listofratings =np.zeros(movies_count)\n",
        "    listofratings[mi-1] =ri\n",
        "    listoflist.append(list(listofratings))\n",
        "  return listoflist\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih9evYMHWX8A"
      },
      "source": [
        "#Modifying training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHWQZkC4opRZ"
      },
      "source": [
        "training_set_1 = modify(training_set_1)\n",
        "test_set_1 = modify(test_set_1)\n",
        "\n",
        "training_set_2 = modify(training_set_2)\n",
        "test_set_2 = modify(test_set_2)\n",
        "\n",
        "training_set_3 = modify(training_set_3)\n",
        "test_set_3 = modify(test_set_3)\n",
        "\n",
        "training_set_4 = modify(training_set_4)\n",
        "test_set_4 = modify(test_set_4)\n",
        "\n",
        "training_set_5 = modify(training_set_5)\n",
        "test_set_5 = modify(test_set_5)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbOBrIWM8rEJ"
      },
      "source": [
        "# Converting the data into Torch tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AFjbHEtC3mN"
      },
      "source": [
        "\n",
        "training_set_1=torch.FloatTensor(training_set_1)\n",
        "test_set_1=torch.FloatTensor(test_set_1)\n",
        "\n",
        "training_set_2=torch.FloatTensor(training_set_2)\n",
        "test_set_2=torch.FloatTensor(test_set_2)\n",
        "\n",
        "training_set_3=torch.FloatTensor(training_set_3)\n",
        "test_set_3=torch.FloatTensor(test_set_3)\n",
        "\n",
        "training_set_4=torch.FloatTensor(training_set_4)\n",
        "test_set_4=torch.FloatTensor(test_set_4)\n",
        "\n",
        "training_set_5=torch.FloatTensor(training_set_5)\n",
        "test_set_5=torch.FloatTensor(test_set_5)\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE94axPGorqc"
      },
      "source": [
        "# Converting the data into Torch tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI3uVFczoujP"
      },
      "source": [
        "training_set_1=torch.FloatTensor(training_set_1)\n",
        "test_set_1=torch.FloatTensor(test_set_1)\n",
        "\n",
        "training_set_2=torch.FloatTensor(training_set_2)\n",
        "test_set_2=torch.FloatTensor(test_set_2)\n",
        "\n",
        "training_set_3=torch.FloatTensor(training_set_3)\n",
        "test_set_3=torch.FloatTensor(test_set_3)\n",
        "\n",
        "training_set_4=torch.FloatTensor(training_set_4)\n",
        "test_set_4=torch.FloatTensor(test_set_4)\n",
        "\n",
        "training_set_5=torch.FloatTensor(training_set_5)\n",
        "test_set_5=torch.FloatTensor(test_set_5)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3rNJjyVowqW"
      },
      "source": [
        "# Creating the architecture of the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INoRqw3_ozkH"
      },
      "source": [
        "class MODELL(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super(MODELL, self).__init__()\n",
        "        self.layer1 =nn.Linear(movies_count, 20)\n",
        "        self.layer2 =nn.Linear(20, 10)\n",
        "        self.layer3 =nn.Linear(10, 20)\n",
        "        self.layer4 =nn.Linear(20, movies_count)\n",
        "        self.activation = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        x =self.activation(self.layer1(x))\n",
        "        x =self.activation(self.layer2(x))\n",
        "        x =self.activation(self.layer3(x))\n",
        "        x =self.layer4(x)\n",
        "        return x\n",
        "\n",
        "archi = MODELL()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.RMSprop(archi.parameters(), lr = 0.01, weight_decay = 0.5)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09xMbtODo2em"
      },
      "source": [
        "# Training the Autoencoder part : 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i9Jn9rbo5i1",
        "outputId": "e044abe5-8baf-4be2-ccc4-9475a0f84f7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "e_counts = 100\n",
        "for epoch in range(e_counts):\n",
        "  train_loss1 , s1 =0 , 0.                                    \n",
        "  for ui in range(user_count):\n",
        "    input_info = Variable(training_set_1[ui]).unsqueeze(0)\n",
        "    target_info = input_info.clone()\n",
        "    if torch.sum(target_info.data > 0) > 0:\n",
        "      output_info =archi(input_info)\n",
        "      target_info.require_grad = False\n",
        "      output_info[target_info ==0] =0\n",
        "      l =criterion(output_info, target_info)\n",
        "      adj_cons = movies_count/float(torch.sum(target_info.data > 0) + 1e-10)\n",
        "      l.backward()\n",
        "      train_loss1 +=np.sqrt(l.data*adj_cons)\n",
        "      s1 +=1.\n",
        "      optimizer.step()\n",
        "  print('train_1 loss at epoch number '+ str(epoch+1)+ ' is ' +str(train_loss1/s1))\n",
        "print()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_1 loss at epoch number 1 is tensor(1.8681)\n",
            "train_1 loss at epoch number 2 is tensor(1.1532)\n",
            "train_1 loss at epoch number 3 is tensor(1.0781)\n",
            "train_1 loss at epoch number 4 is tensor(1.0511)\n",
            "train_1 loss at epoch number 5 is tensor(1.0382)\n",
            "train_1 loss at epoch number 6 is tensor(1.0300)\n",
            "train_1 loss at epoch number 7 is tensor(1.0243)\n",
            "train_1 loss at epoch number 8 is tensor(1.0207)\n",
            "train_1 loss at epoch number 9 is tensor(1.0182)\n",
            "train_1 loss at epoch number 10 is tensor(1.0161)\n",
            "train_1 loss at epoch number 11 is tensor(1.0147)\n",
            "train_1 loss at epoch number 12 is tensor(1.0136)\n",
            "train_1 loss at epoch number 13 is tensor(1.0125)\n",
            "train_1 loss at epoch number 14 is tensor(1.0118)\n",
            "train_1 loss at epoch number 15 is tensor(1.0114)\n",
            "train_1 loss at epoch number 16 is tensor(1.0107)\n",
            "train_1 loss at epoch number 17 is tensor(1.0101)\n",
            "train_1 loss at epoch number 18 is tensor(1.0098)\n",
            "train_1 loss at epoch number 19 is tensor(1.0092)\n",
            "train_1 loss at epoch number 20 is tensor(1.0090)\n",
            "train_1 loss at epoch number 21 is tensor(1.0086)\n",
            "train_1 loss at epoch number 22 is tensor(1.0084)\n",
            "train_1 loss at epoch number 23 is tensor(1.0085)\n",
            "train_1 loss at epoch number 24 is tensor(1.0082)\n",
            "train_1 loss at epoch number 25 is tensor(1.0082)\n",
            "train_1 loss at epoch number 26 is tensor(1.0079)\n",
            "train_1 loss at epoch number 27 is tensor(1.0078)\n",
            "train_1 loss at epoch number 28 is tensor(1.0078)\n",
            "train_1 loss at epoch number 29 is tensor(1.0074)\n",
            "train_1 loss at epoch number 30 is tensor(1.0069)\n",
            "train_1 loss at epoch number 31 is tensor(1.0057)\n",
            "train_1 loss at epoch number 32 is tensor(1.0042)\n",
            "train_1 loss at epoch number 33 is tensor(1.0039)\n",
            "train_1 loss at epoch number 34 is tensor(1.0024)\n",
            "train_1 loss at epoch number 35 is tensor(1.0020)\n",
            "train_1 loss at epoch number 36 is tensor(0.9996)\n",
            "train_1 loss at epoch number 37 is tensor(0.9993)\n",
            "train_1 loss at epoch number 38 is tensor(0.9971)\n",
            "train_1 loss at epoch number 39 is tensor(0.9970)\n",
            "train_1 loss at epoch number 40 is tensor(0.9948)\n",
            "train_1 loss at epoch number 41 is tensor(0.9933)\n",
            "train_1 loss at epoch number 42 is tensor(0.9921)\n",
            "train_1 loss at epoch number 43 is tensor(0.9915)\n",
            "train_1 loss at epoch number 44 is tensor(0.9893)\n",
            "train_1 loss at epoch number 45 is tensor(0.9892)\n",
            "train_1 loss at epoch number 46 is tensor(0.9868)\n",
            "train_1 loss at epoch number 47 is tensor(0.9868)\n",
            "train_1 loss at epoch number 48 is tensor(0.9847)\n",
            "train_1 loss at epoch number 49 is tensor(0.9842)\n",
            "train_1 loss at epoch number 50 is tensor(0.9825)\n",
            "train_1 loss at epoch number 51 is tensor(0.9816)\n",
            "train_1 loss at epoch number 52 is tensor(0.9799)\n",
            "train_1 loss at epoch number 53 is tensor(0.9794)\n",
            "train_1 loss at epoch number 54 is tensor(0.9770)\n",
            "train_1 loss at epoch number 55 is tensor(0.9769)\n",
            "train_1 loss at epoch number 56 is tensor(0.9747)\n",
            "train_1 loss at epoch number 57 is tensor(0.9752)\n",
            "train_1 loss at epoch number 58 is tensor(0.9725)\n",
            "train_1 loss at epoch number 59 is tensor(0.9729)\n",
            "train_1 loss at epoch number 60 is tensor(0.9705)\n",
            "train_1 loss at epoch number 61 is tensor(0.9711)\n",
            "train_1 loss at epoch number 62 is tensor(0.9687)\n",
            "train_1 loss at epoch number 63 is tensor(0.9687)\n",
            "train_1 loss at epoch number 64 is tensor(0.9660)\n",
            "train_1 loss at epoch number 65 is tensor(0.9671)\n",
            "train_1 loss at epoch number 66 is tensor(0.9639)\n",
            "train_1 loss at epoch number 67 is tensor(0.9650)\n",
            "train_1 loss at epoch number 68 is tensor(0.9623)\n",
            "train_1 loss at epoch number 69 is tensor(0.9634)\n",
            "train_1 loss at epoch number 70 is tensor(0.9602)\n",
            "train_1 loss at epoch number 71 is tensor(0.9606)\n",
            "train_1 loss at epoch number 72 is tensor(0.9577)\n",
            "train_1 loss at epoch number 73 is tensor(0.9585)\n",
            "train_1 loss at epoch number 74 is tensor(0.9561)\n",
            "train_1 loss at epoch number 75 is tensor(0.9566)\n",
            "train_1 loss at epoch number 76 is tensor(0.9538)\n",
            "train_1 loss at epoch number 77 is tensor(0.9542)\n",
            "train_1 loss at epoch number 78 is tensor(0.9519)\n",
            "train_1 loss at epoch number 79 is tensor(0.9522)\n",
            "train_1 loss at epoch number 80 is tensor(0.9495)\n",
            "train_1 loss at epoch number 81 is tensor(0.9499)\n",
            "train_1 loss at epoch number 82 is tensor(0.9471)\n",
            "train_1 loss at epoch number 83 is tensor(0.9480)\n",
            "train_1 loss at epoch number 84 is tensor(0.9457)\n",
            "train_1 loss at epoch number 85 is tensor(0.9460)\n",
            "train_1 loss at epoch number 86 is tensor(0.9441)\n",
            "train_1 loss at epoch number 87 is tensor(0.9439)\n",
            "train_1 loss at epoch number 88 is tensor(0.9418)\n",
            "train_1 loss at epoch number 89 is tensor(0.9426)\n",
            "train_1 loss at epoch number 90 is tensor(0.9404)\n",
            "train_1 loss at epoch number 91 is tensor(0.9412)\n",
            "train_1 loss at epoch number 92 is tensor(0.9383)\n",
            "train_1 loss at epoch number 93 is tensor(0.9394)\n",
            "train_1 loss at epoch number 94 is tensor(0.9374)\n",
            "train_1 loss at epoch number 95 is tensor(0.9379)\n",
            "train_1 loss at epoch number 96 is tensor(0.9360)\n",
            "train_1 loss at epoch number 97 is tensor(0.9363)\n",
            "train_1 loss at epoch number 98 is tensor(0.9349)\n",
            "train_1 loss at epoch number 99 is tensor(0.9355)\n",
            "train_1 loss at epoch number 100 is tensor(0.9334)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihixW7g4o7y8"
      },
      "source": [
        "# Testing the Autoencoder : part 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Hb9srQBo-S6",
        "outputId": "e94b101b-362f-473d-f213-a0b438c9d909",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "test_loss1 ,s1  = 0 , 0.\n",
        " \n",
        "for ui in range(user_count):\n",
        "  input_info= Variable(training_set_1[ui]).unsqueeze(0)\n",
        "  target_info =Variable(test_set_1[ui]).unsqueeze(0)\n",
        "  if torch.sum(target_info.data>0)> 0:\n",
        "    output_info =archi(input_info)\n",
        "    target_info.require_grad= False\n",
        "    output_info[target_info== 0] = 0\n",
        "    l= criterion(output_info, target_info)\n",
        "    adj_cons =movies_count/float(torch.sum(target_info.data > 0) + 1e-10)\n",
        "    test_loss1 += np.sqrt(l.data*adj_cons)\n",
        "    s1+= 1.\n",
        "print('test_1 loss: '+str(test_loss1/s1))\n",
        "print()\n",
        "\n",
        "\n",
        "archi = MODELL()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.RMSprop(archi.parameters(), lr = 0.01, weight_decay = 0.5)\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_1 loss: tensor(0.9848)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jZ_KLCyHjTn"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyU8znY_HmHf"
      },
      "source": [
        "#Training the Autoencoder : part 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80KoCt6fHo0x",
        "outputId": "e3a5f987-fe39-4bfc-efb6-7c2f88a5803d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "e_counts = 100\n",
        "for epoch in range(e_counts):\n",
        "  train_loss2 , s2 =0 , 0.                                    \n",
        "  for ui in range(user_count):\n",
        "    input_info = Variable(training_set_2[ui]).unsqueeze(0)\n",
        "    target_info = input_info.clone()\n",
        "    if torch.sum(target_info.data > 0) > 0:\n",
        "      output_info =archi(input_info)\n",
        "      target_info.require_grad = False\n",
        "      output_info[target_info ==0] =0\n",
        "      l =criterion(output_info, target_info)\n",
        "      adj_cons = movies_count/float(torch.sum(target_info.data > 0) + 1e-10)\n",
        "      l.backward()\n",
        "      train_loss2 +=np.sqrt(l.data*adj_cons)\n",
        "      s2 +=1.\n",
        "      optimizer.step()\n",
        "  print('train_2 loss at epoch number '+ str(epoch+1)+ ' is ' +str(train_loss2/s2))\n",
        "print()\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_2 loss at epoch number 1 is tensor(1.8684)\n",
            "train_2 loss at epoch number 2 is tensor(1.1532)\n",
            "train_2 loss at epoch number 3 is tensor(1.0782)\n",
            "train_2 loss at epoch number 4 is tensor(1.0511)\n",
            "train_2 loss at epoch number 5 is tensor(1.0375)\n",
            "train_2 loss at epoch number 6 is tensor(1.0301)\n",
            "train_2 loss at epoch number 7 is tensor(1.0249)\n",
            "train_2 loss at epoch number 8 is tensor(1.0205)\n",
            "train_2 loss at epoch number 9 is tensor(1.0183)\n",
            "train_2 loss at epoch number 10 is tensor(1.0163)\n",
            "train_2 loss at epoch number 11 is tensor(1.0148)\n",
            "train_2 loss at epoch number 12 is tensor(1.0138)\n",
            "train_2 loss at epoch number 13 is tensor(1.0132)\n",
            "train_2 loss at epoch number 14 is tensor(1.0114)\n",
            "train_2 loss at epoch number 15 is tensor(1.0115)\n",
            "train_2 loss at epoch number 16 is tensor(1.0103)\n",
            "train_2 loss at epoch number 17 is tensor(1.0103)\n",
            "train_2 loss at epoch number 18 is tensor(1.0095)\n",
            "train_2 loss at epoch number 19 is tensor(1.0095)\n",
            "train_2 loss at epoch number 20 is tensor(1.0092)\n",
            "train_2 loss at epoch number 21 is tensor(1.0087)\n",
            "train_2 loss at epoch number 22 is tensor(1.0085)\n",
            "train_2 loss at epoch number 23 is tensor(1.0081)\n",
            "train_2 loss at epoch number 24 is tensor(1.0083)\n",
            "train_2 loss at epoch number 25 is tensor(1.0078)\n",
            "train_2 loss at epoch number 26 is tensor(1.0079)\n",
            "train_2 loss at epoch number 27 is tensor(1.0079)\n",
            "train_2 loss at epoch number 28 is tensor(1.0082)\n",
            "train_2 loss at epoch number 29 is tensor(1.0073)\n",
            "train_2 loss at epoch number 30 is tensor(1.0066)\n",
            "train_2 loss at epoch number 31 is tensor(1.0063)\n",
            "train_2 loss at epoch number 32 is tensor(1.0042)\n",
            "train_2 loss at epoch number 33 is tensor(1.0043)\n",
            "train_2 loss at epoch number 34 is tensor(1.0023)\n",
            "train_2 loss at epoch number 35 is tensor(1.0022)\n",
            "train_2 loss at epoch number 36 is tensor(0.9997)\n",
            "train_2 loss at epoch number 37 is tensor(0.9988)\n",
            "train_2 loss at epoch number 38 is tensor(0.9969)\n",
            "train_2 loss at epoch number 39 is tensor(0.9967)\n",
            "train_2 loss at epoch number 40 is tensor(0.9944)\n",
            "train_2 loss at epoch number 41 is tensor(0.9932)\n",
            "train_2 loss at epoch number 42 is tensor(0.9916)\n",
            "train_2 loss at epoch number 43 is tensor(0.9911)\n",
            "train_2 loss at epoch number 44 is tensor(0.9890)\n",
            "train_2 loss at epoch number 45 is tensor(0.9891)\n",
            "train_2 loss at epoch number 46 is tensor(0.9869)\n",
            "train_2 loss at epoch number 47 is tensor(0.9865)\n",
            "train_2 loss at epoch number 48 is tensor(0.9845)\n",
            "train_2 loss at epoch number 49 is tensor(0.9842)\n",
            "train_2 loss at epoch number 50 is tensor(0.9820)\n",
            "train_2 loss at epoch number 51 is tensor(0.9814)\n",
            "train_2 loss at epoch number 52 is tensor(0.9794)\n",
            "train_2 loss at epoch number 53 is tensor(0.9795)\n",
            "train_2 loss at epoch number 54 is tensor(0.9765)\n",
            "train_2 loss at epoch number 55 is tensor(0.9766)\n",
            "train_2 loss at epoch number 56 is tensor(0.9743)\n",
            "train_2 loss at epoch number 57 is tensor(0.9746)\n",
            "train_2 loss at epoch number 58 is tensor(0.9724)\n",
            "train_2 loss at epoch number 59 is tensor(0.9722)\n",
            "train_2 loss at epoch number 60 is tensor(0.9700)\n",
            "train_2 loss at epoch number 61 is tensor(0.9702)\n",
            "train_2 loss at epoch number 62 is tensor(0.9679)\n",
            "train_2 loss at epoch number 63 is tensor(0.9685)\n",
            "train_2 loss at epoch number 64 is tensor(0.9653)\n",
            "train_2 loss at epoch number 65 is tensor(0.9660)\n",
            "train_2 loss at epoch number 66 is tensor(0.9634)\n",
            "train_2 loss at epoch number 67 is tensor(0.9645)\n",
            "train_2 loss at epoch number 68 is tensor(0.9614)\n",
            "train_2 loss at epoch number 69 is tensor(0.9622)\n",
            "train_2 loss at epoch number 70 is tensor(0.9590)\n",
            "train_2 loss at epoch number 71 is tensor(0.9595)\n",
            "train_2 loss at epoch number 72 is tensor(0.9569)\n",
            "train_2 loss at epoch number 73 is tensor(0.9576)\n",
            "train_2 loss at epoch number 74 is tensor(0.9545)\n",
            "train_2 loss at epoch number 75 is tensor(0.9550)\n",
            "train_2 loss at epoch number 76 is tensor(0.9524)\n",
            "train_2 loss at epoch number 77 is tensor(0.9533)\n",
            "train_2 loss at epoch number 78 is tensor(0.9502)\n",
            "train_2 loss at epoch number 79 is tensor(0.9508)\n",
            "train_2 loss at epoch number 80 is tensor(0.9479)\n",
            "train_2 loss at epoch number 81 is tensor(0.9488)\n",
            "train_2 loss at epoch number 82 is tensor(0.9460)\n",
            "train_2 loss at epoch number 83 is tensor(0.9467)\n",
            "train_2 loss at epoch number 84 is tensor(0.9439)\n",
            "train_2 loss at epoch number 85 is tensor(0.9444)\n",
            "train_2 loss at epoch number 86 is tensor(0.9423)\n",
            "train_2 loss at epoch number 87 is tensor(0.9430)\n",
            "train_2 loss at epoch number 88 is tensor(0.9408)\n",
            "train_2 loss at epoch number 89 is tensor(0.9414)\n",
            "train_2 loss at epoch number 90 is tensor(0.9390)\n",
            "train_2 loss at epoch number 91 is tensor(0.9402)\n",
            "train_2 loss at epoch number 92 is tensor(0.9375)\n",
            "train_2 loss at epoch number 93 is tensor(0.9388)\n",
            "train_2 loss at epoch number 94 is tensor(0.9360)\n",
            "train_2 loss at epoch number 95 is tensor(0.9374)\n",
            "train_2 loss at epoch number 96 is tensor(0.9350)\n",
            "train_2 loss at epoch number 97 is tensor(0.9361)\n",
            "train_2 loss at epoch number 98 is tensor(0.9334)\n",
            "train_2 loss at epoch number 99 is tensor(0.9350)\n",
            "train_2 loss at epoch number 100 is tensor(0.9323)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmQb95WFH3df"
      },
      "source": [
        "#Testing the Autoencode : part 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlLnkrnXH84O",
        "outputId": "41e37403-ce27-438b-fbec-d5ea5752e4be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_loss2 ,s2  = 0 , 0.\n",
        " \n",
        "for ui in range(user_count):\n",
        "  input_info= Variable(training_set_2[ui]).unsqueeze(0)\n",
        "  target_info =Variable(test_set_2[ui]).unsqueeze(0)\n",
        "  if torch.sum(target_info.data>0)> 0:\n",
        "    output_info =archi(input_info)\n",
        "    target_info.require_grad= False\n",
        "    output_info[target_info== 0] = 0\n",
        "    l= criterion(output_info, target_info)\n",
        "    adj_cons =movies_count/float(torch.sum(target_info.data > 0) + 1e-10)\n",
        "    test_loss2 += np.sqrt(l.data*adj_cons)\n",
        "    s2+= 1.\n",
        "print('test_2 loss: '+str(test_loss2/s2))\n",
        "print()\n",
        "\n",
        "\n",
        "archi = MODELL()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.RMSprop(archi.parameters(), lr = 0.01, weight_decay = 0.5)\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_2 loss: tensor(0.9835)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMW0S4JjIAq-"
      },
      "source": [
        "#Training the autoencoder : part 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtSCJs3yIGZ-",
        "outputId": "305b93de-96d8-4bb5-8ca7-eb4bf8f7d42b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "e_counts = 100\n",
        "for epoch in range(e_counts):\n",
        "  train_loss3 , s3 =0 , 0.                                    \n",
        "  for ui in range(user_count):\n",
        "    input_info = Variable(training_set_3[ui]).unsqueeze(0)\n",
        "    target_info = input_info.clone()\n",
        "    if torch.sum(target_info.data > 0) > 0:\n",
        "      output_info =archi(input_info)\n",
        "      target_info.require_grad = False\n",
        "      output_info[target_info ==0] =0\n",
        "      l =criterion(output_info, target_info)\n",
        "      adj_cons = movies_count/float(torch.sum(target_info.data > 0) + 1e-10)\n",
        "      l.backward()\n",
        "      train_loss3 +=np.sqrt(l.data*adj_cons)\n",
        "      s3 +=1.\n",
        "      optimizer.step()\n",
        "  print('train_3 loss at epoch number '+ str(epoch+1)+ ' is ' +str(train_loss3/s3))\n",
        "print()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_3 loss at epoch number 1 is tensor(1.8688)\n",
            "train_3 loss at epoch number 2 is tensor(1.1530)\n",
            "train_3 loss at epoch number 3 is tensor(1.0780)\n",
            "train_3 loss at epoch number 4 is tensor(1.0511)\n",
            "train_3 loss at epoch number 5 is tensor(1.0375)\n",
            "train_3 loss at epoch number 6 is tensor(1.0298)\n",
            "train_3 loss at epoch number 7 is tensor(1.0247)\n",
            "train_3 loss at epoch number 8 is tensor(1.0206)\n",
            "train_3 loss at epoch number 9 is tensor(1.0185)\n",
            "train_3 loss at epoch number 10 is tensor(1.0161)\n",
            "train_3 loss at epoch number 11 is tensor(1.0145)\n",
            "train_3 loss at epoch number 12 is tensor(1.0133)\n",
            "train_3 loss at epoch number 13 is tensor(1.0127)\n",
            "train_3 loss at epoch number 14 is tensor(1.0115)\n",
            "train_3 loss at epoch number 15 is tensor(1.0112)\n",
            "train_3 loss at epoch number 16 is tensor(1.0102)\n",
            "train_3 loss at epoch number 17 is tensor(1.0103)\n",
            "train_3 loss at epoch number 18 is tensor(1.0097)\n",
            "train_3 loss at epoch number 19 is tensor(1.0092)\n",
            "train_3 loss at epoch number 20 is tensor(1.0090)\n",
            "train_3 loss at epoch number 21 is tensor(1.0086)\n",
            "train_3 loss at epoch number 22 is tensor(1.0088)\n",
            "train_3 loss at epoch number 23 is tensor(1.0084)\n",
            "train_3 loss at epoch number 24 is tensor(1.0081)\n",
            "train_3 loss at epoch number 25 is tensor(1.0080)\n",
            "train_3 loss at epoch number 26 is tensor(1.0078)\n",
            "train_3 loss at epoch number 27 is tensor(1.0076)\n",
            "train_3 loss at epoch number 28 is tensor(1.0079)\n",
            "train_3 loss at epoch number 29 is tensor(1.0070)\n",
            "train_3 loss at epoch number 30 is tensor(1.0068)\n",
            "train_3 loss at epoch number 31 is tensor(1.0061)\n",
            "train_3 loss at epoch number 32 is tensor(1.0042)\n",
            "train_3 loss at epoch number 33 is tensor(1.0040)\n",
            "train_3 loss at epoch number 34 is tensor(1.0021)\n",
            "train_3 loss at epoch number 35 is tensor(1.0019)\n",
            "train_3 loss at epoch number 36 is tensor(0.9994)\n",
            "train_3 loss at epoch number 37 is tensor(0.9991)\n",
            "train_3 loss at epoch number 38 is tensor(0.9968)\n",
            "train_3 loss at epoch number 39 is tensor(0.9962)\n",
            "train_3 loss at epoch number 40 is tensor(0.9944)\n",
            "train_3 loss at epoch number 41 is tensor(0.9934)\n",
            "train_3 loss at epoch number 42 is tensor(0.9909)\n",
            "train_3 loss at epoch number 43 is tensor(0.9908)\n",
            "train_3 loss at epoch number 44 is tensor(0.9889)\n",
            "train_3 loss at epoch number 45 is tensor(0.9888)\n",
            "train_3 loss at epoch number 46 is tensor(0.9864)\n",
            "train_3 loss at epoch number 47 is tensor(0.9866)\n",
            "train_3 loss at epoch number 48 is tensor(0.9844)\n",
            "train_3 loss at epoch number 49 is tensor(0.9836)\n",
            "train_3 loss at epoch number 50 is tensor(0.9815)\n",
            "train_3 loss at epoch number 51 is tensor(0.9807)\n",
            "train_3 loss at epoch number 52 is tensor(0.9791)\n",
            "train_3 loss at epoch number 53 is tensor(0.9789)\n",
            "train_3 loss at epoch number 54 is tensor(0.9766)\n",
            "train_3 loss at epoch number 55 is tensor(0.9766)\n",
            "train_3 loss at epoch number 56 is tensor(0.9741)\n",
            "train_3 loss at epoch number 57 is tensor(0.9740)\n",
            "train_3 loss at epoch number 58 is tensor(0.9715)\n",
            "train_3 loss at epoch number 59 is tensor(0.9716)\n",
            "train_3 loss at epoch number 60 is tensor(0.9696)\n",
            "train_3 loss at epoch number 61 is tensor(0.9697)\n",
            "train_3 loss at epoch number 62 is tensor(0.9669)\n",
            "train_3 loss at epoch number 63 is tensor(0.9675)\n",
            "train_3 loss at epoch number 64 is tensor(0.9652)\n",
            "train_3 loss at epoch number 65 is tensor(0.9657)\n",
            "train_3 loss at epoch number 66 is tensor(0.9630)\n",
            "train_3 loss at epoch number 67 is tensor(0.9636)\n",
            "train_3 loss at epoch number 68 is tensor(0.9611)\n",
            "train_3 loss at epoch number 69 is tensor(0.9618)\n",
            "train_3 loss at epoch number 70 is tensor(0.9588)\n",
            "train_3 loss at epoch number 71 is tensor(0.9595)\n",
            "train_3 loss at epoch number 72 is tensor(0.9567)\n",
            "train_3 loss at epoch number 73 is tensor(0.9576)\n",
            "train_3 loss at epoch number 74 is tensor(0.9554)\n",
            "train_3 loss at epoch number 75 is tensor(0.9556)\n",
            "train_3 loss at epoch number 76 is tensor(0.9535)\n",
            "train_3 loss at epoch number 77 is tensor(0.9531)\n",
            "train_3 loss at epoch number 78 is tensor(0.9513)\n",
            "train_3 loss at epoch number 79 is tensor(0.9514)\n",
            "train_3 loss at epoch number 80 is tensor(0.9497)\n",
            "train_3 loss at epoch number 81 is tensor(0.9497)\n",
            "train_3 loss at epoch number 82 is tensor(0.9476)\n",
            "train_3 loss at epoch number 83 is tensor(0.9478)\n",
            "train_3 loss at epoch number 84 is tensor(0.9454)\n",
            "train_3 loss at epoch number 85 is tensor(0.9456)\n",
            "train_3 loss at epoch number 86 is tensor(0.9439)\n",
            "train_3 loss at epoch number 87 is tensor(0.9444)\n",
            "train_3 loss at epoch number 88 is tensor(0.9420)\n",
            "train_3 loss at epoch number 89 is tensor(0.9425)\n",
            "train_3 loss at epoch number 90 is tensor(0.9402)\n",
            "train_3 loss at epoch number 91 is tensor(0.9411)\n",
            "train_3 loss at epoch number 92 is tensor(0.9389)\n",
            "train_3 loss at epoch number 93 is tensor(0.9400)\n",
            "train_3 loss at epoch number 94 is tensor(0.9374)\n",
            "train_3 loss at epoch number 95 is tensor(0.9384)\n",
            "train_3 loss at epoch number 96 is tensor(0.9361)\n",
            "train_3 loss at epoch number 97 is tensor(0.9369)\n",
            "train_3 loss at epoch number 98 is tensor(0.9349)\n",
            "train_3 loss at epoch number 99 is tensor(0.9361)\n",
            "train_3 loss at epoch number 100 is tensor(0.9342)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbRbSYfNIL_C"
      },
      "source": [
        "#Testing the autoencoder : part 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7vvBOGVIRrQ",
        "outputId": "5981b145-e37a-43be-96c8-23ad58f55291",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_loss3 ,s3  = 0 , 0.\n",
        " \n",
        "for ui in range(user_count):\n",
        "  input_info= Variable(training_set_3[ui]).unsqueeze(0)\n",
        "  target_info =Variable(test_set_3[ui]).unsqueeze(0)\n",
        "  if torch.sum(target_info.data>0)> 0:\n",
        "    output_info =archi(input_info)\n",
        "    target_info.require_grad= False\n",
        "    output_info[target_info== 0] = 0\n",
        "    l= criterion(output_info, target_info)\n",
        "    adj_cons =movies_count/float(torch.sum(target_info.data > 0) + 1e-10)\n",
        "    test_loss3 += np.sqrt(l.data*adj_cons)\n",
        "    s3+= 1.\n",
        "print('test_3 loss: '+str(test_loss3/s3))\n",
        "print()\n",
        "\n",
        "archi = MODELL()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.RMSprop(archi.parameters(), lr = 0.01, weight_decay = 0.5)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_3 loss: tensor(0.9847)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thUNi1TVIWJH"
      },
      "source": [
        "#Training the autoencoder : part 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxgiOjdLIaA3",
        "outputId": "c87841bf-1088-401b-b26b-ef263a455467",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "e_counts = 100\n",
        "for epoch in range(e_counts):\n",
        "  train_loss4 , s4 =0 , 0.                                    \n",
        "  for ui in range(user_count):\n",
        "    input_info = Variable(training_set_4[ui]).unsqueeze(0)\n",
        "    target_info = input_info.clone()\n",
        "    if torch.sum(target_info.data > 0) > 0:\n",
        "      output_info =archi(input_info)\n",
        "      target_info.require_grad = False\n",
        "      output_info[target_info ==0] =0\n",
        "      l =criterion(output_info, target_info)\n",
        "      adj_cons = movies_count/float(torch.sum(target_info.data > 0) + 1e-10)\n",
        "      l.backward()\n",
        "      train_loss4 +=np.sqrt(l.data*adj_cons)\n",
        "      s4 +=1.\n",
        "      optimizer.step()\n",
        "  print('train_4 loss at epoch number '+ str(epoch+1)+ ' is ' +str(train_loss4/s4))\n",
        "print()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_4 loss at epoch number 1 is tensor(1.8683)\n",
            "train_4 loss at epoch number 2 is tensor(1.1530)\n",
            "train_4 loss at epoch number 3 is tensor(1.0781)\n",
            "train_4 loss at epoch number 4 is tensor(1.0515)\n",
            "train_4 loss at epoch number 5 is tensor(1.0378)\n",
            "train_4 loss at epoch number 6 is tensor(1.0297)\n",
            "train_4 loss at epoch number 7 is tensor(1.0247)\n",
            "train_4 loss at epoch number 8 is tensor(1.0213)\n",
            "train_4 loss at epoch number 9 is tensor(1.0182)\n",
            "train_4 loss at epoch number 10 is tensor(1.0163)\n",
            "train_4 loss at epoch number 11 is tensor(1.0148)\n",
            "train_4 loss at epoch number 12 is tensor(1.0134)\n",
            "train_4 loss at epoch number 13 is tensor(1.0128)\n",
            "train_4 loss at epoch number 14 is tensor(1.0118)\n",
            "train_4 loss at epoch number 15 is tensor(1.0111)\n",
            "train_4 loss at epoch number 16 is tensor(1.0104)\n",
            "train_4 loss at epoch number 17 is tensor(1.0099)\n",
            "train_4 loss at epoch number 18 is tensor(1.0100)\n",
            "train_4 loss at epoch number 19 is tensor(1.0096)\n",
            "train_4 loss at epoch number 20 is tensor(1.0090)\n",
            "train_4 loss at epoch number 21 is tensor(1.0090)\n",
            "train_4 loss at epoch number 22 is tensor(1.0084)\n",
            "train_4 loss at epoch number 23 is tensor(1.0085)\n",
            "train_4 loss at epoch number 24 is tensor(1.0082)\n",
            "train_4 loss at epoch number 25 is tensor(1.0082)\n",
            "train_4 loss at epoch number 26 is tensor(1.0079)\n",
            "train_4 loss at epoch number 27 is tensor(1.0076)\n",
            "train_4 loss at epoch number 28 is tensor(1.0076)\n",
            "train_4 loss at epoch number 29 is tensor(1.0073)\n",
            "train_4 loss at epoch number 30 is tensor(1.0069)\n",
            "train_4 loss at epoch number 31 is tensor(1.0062)\n",
            "train_4 loss at epoch number 32 is tensor(1.0040)\n",
            "train_4 loss at epoch number 33 is tensor(1.0044)\n",
            "train_4 loss at epoch number 34 is tensor(1.0023)\n",
            "train_4 loss at epoch number 35 is tensor(1.0022)\n",
            "train_4 loss at epoch number 36 is tensor(0.9997)\n",
            "train_4 loss at epoch number 37 is tensor(0.9994)\n",
            "train_4 loss at epoch number 38 is tensor(0.9965)\n",
            "train_4 loss at epoch number 39 is tensor(0.9966)\n",
            "train_4 loss at epoch number 40 is tensor(0.9943)\n",
            "train_4 loss at epoch number 41 is tensor(0.9936)\n",
            "train_4 loss at epoch number 42 is tensor(0.9911)\n",
            "train_4 loss at epoch number 43 is tensor(0.9914)\n",
            "train_4 loss at epoch number 44 is tensor(0.9891)\n",
            "train_4 loss at epoch number 45 is tensor(0.9887)\n",
            "train_4 loss at epoch number 46 is tensor(0.9866)\n",
            "train_4 loss at epoch number 47 is tensor(0.9860)\n",
            "train_4 loss at epoch number 48 is tensor(0.9846)\n",
            "train_4 loss at epoch number 49 is tensor(0.9841)\n",
            "train_4 loss at epoch number 50 is tensor(0.9819)\n",
            "train_4 loss at epoch number 51 is tensor(0.9813)\n",
            "train_4 loss at epoch number 52 is tensor(0.9794)\n",
            "train_4 loss at epoch number 53 is tensor(0.9788)\n",
            "train_4 loss at epoch number 54 is tensor(0.9762)\n",
            "train_4 loss at epoch number 55 is tensor(0.9765)\n",
            "train_4 loss at epoch number 56 is tensor(0.9743)\n",
            "train_4 loss at epoch number 57 is tensor(0.9740)\n",
            "train_4 loss at epoch number 58 is tensor(0.9722)\n",
            "train_4 loss at epoch number 59 is tensor(0.9716)\n",
            "train_4 loss at epoch number 60 is tensor(0.9697)\n",
            "train_4 loss at epoch number 61 is tensor(0.9701)\n",
            "train_4 loss at epoch number 62 is tensor(0.9673)\n",
            "train_4 loss at epoch number 63 is tensor(0.9679)\n",
            "train_4 loss at epoch number 64 is tensor(0.9653)\n",
            "train_4 loss at epoch number 65 is tensor(0.9662)\n",
            "train_4 loss at epoch number 66 is tensor(0.9633)\n",
            "train_4 loss at epoch number 67 is tensor(0.9645)\n",
            "train_4 loss at epoch number 68 is tensor(0.9604)\n",
            "train_4 loss at epoch number 69 is tensor(0.9621)\n",
            "train_4 loss at epoch number 70 is tensor(0.9587)\n",
            "train_4 loss at epoch number 71 is tensor(0.9603)\n",
            "train_4 loss at epoch number 72 is tensor(0.9571)\n",
            "train_4 loss at epoch number 73 is tensor(0.9580)\n",
            "train_4 loss at epoch number 74 is tensor(0.9549)\n",
            "train_4 loss at epoch number 75 is tensor(0.9562)\n",
            "train_4 loss at epoch number 76 is tensor(0.9529)\n",
            "train_4 loss at epoch number 77 is tensor(0.9542)\n",
            "train_4 loss at epoch number 78 is tensor(0.9512)\n",
            "train_4 loss at epoch number 79 is tensor(0.9513)\n",
            "train_4 loss at epoch number 80 is tensor(0.9487)\n",
            "train_4 loss at epoch number 81 is tensor(0.9504)\n",
            "train_4 loss at epoch number 82 is tensor(0.9477)\n",
            "train_4 loss at epoch number 83 is tensor(0.9486)\n",
            "train_4 loss at epoch number 84 is tensor(0.9461)\n",
            "train_4 loss at epoch number 85 is tensor(0.9468)\n",
            "train_4 loss at epoch number 86 is tensor(0.9439)\n",
            "train_4 loss at epoch number 87 is tensor(0.9447)\n",
            "train_4 loss at epoch number 88 is tensor(0.9419)\n",
            "train_4 loss at epoch number 89 is tensor(0.9437)\n",
            "train_4 loss at epoch number 90 is tensor(0.9405)\n",
            "train_4 loss at epoch number 91 is tensor(0.9416)\n",
            "train_4 loss at epoch number 92 is tensor(0.9388)\n",
            "train_4 loss at epoch number 93 is tensor(0.9406)\n",
            "train_4 loss at epoch number 94 is tensor(0.9377)\n",
            "train_4 loss at epoch number 95 is tensor(0.9390)\n",
            "train_4 loss at epoch number 96 is tensor(0.9360)\n",
            "train_4 loss at epoch number 97 is tensor(0.9381)\n",
            "train_4 loss at epoch number 98 is tensor(0.9351)\n",
            "train_4 loss at epoch number 99 is tensor(0.9369)\n",
            "train_4 loss at epoch number 100 is tensor(0.9335)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A16NKYcVIcnA"
      },
      "source": [
        "#Testing the autoencoder : part 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I1yiLj8If6B",
        "outputId": "e4eb038c-7d6f-46e1-d542-e48019c4d238",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "test_loss4 ,s4  = 0 , 0.\n",
        " \n",
        "for ui in range(user_count):\n",
        "  input_info= Variable(training_set_4[ui]).unsqueeze(0)\n",
        "  target_info =Variable(test_set_4[ui]).unsqueeze(0)\n",
        "  if torch.sum(target_info.data>0)> 0:\n",
        "    output_info =archi(input_info)\n",
        "    target_info.require_grad= False\n",
        "    output_info[target_info== 0] = 0\n",
        "    l= criterion(output_info, target_info)\n",
        "    adj_cons =movies_count/float(torch.sum(target_info.data > 0) + 1e-10)\n",
        "    test_loss4 += np.sqrt(l.data*adj_cons)\n",
        "    s4+= 1.\n",
        "print('test_4 loss: '+str(test_loss4/s4))\n",
        "print()\n",
        "\n",
        "archi = MODELL()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.RMSprop(archi.parameters(), lr = 0.01, weight_decay = 0.5)\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_4 loss: tensor(0.9858)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGaBZw-DIib2"
      },
      "source": [
        "#Training the autoencoder : part 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ifm9cdgIkuA",
        "outputId": "1d6af915-28f0-4ef0-f573-c57e4502582c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "e_counts = 100\n",
        "for epoch in range(e_counts):\n",
        "  train_loss5 , s5 =0 , 0.                                    \n",
        "  for ui in range(user_count):\n",
        "    input_info = Variable(training_set_5[ui]).unsqueeze(0)\n",
        "    target_info = input_info.clone()\n",
        "    if torch.sum(target_info.data > 0) > 0:\n",
        "      output_info =archi(input_info)\n",
        "      target_info.require_grad = False\n",
        "      output_info[target_info ==0] =0\n",
        "      l =criterion(output_info, target_info)\n",
        "      adj_cons = movies_count/float(torch.sum(target_info.data > 0) + 1e-10)\n",
        "      l.backward()\n",
        "      train_loss5 +=np.sqrt(l.data*adj_cons)\n",
        "      s5 +=1.\n",
        "      optimizer.step()\n",
        "  print('train_5 loss at epoch number '+ str(epoch+1)+ ' is ' +str(train_loss5/s5))\n",
        "print()\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_5 loss at epoch number 1 is tensor(1.8679)\n",
            "train_5 loss at epoch number 2 is tensor(1.1530)\n",
            "train_5 loss at epoch number 3 is tensor(1.0779)\n",
            "train_5 loss at epoch number 4 is tensor(1.0510)\n",
            "train_5 loss at epoch number 5 is tensor(1.0377)\n",
            "train_5 loss at epoch number 6 is tensor(1.0298)\n",
            "train_5 loss at epoch number 7 is tensor(1.0249)\n",
            "train_5 loss at epoch number 8 is tensor(1.0209)\n",
            "train_5 loss at epoch number 9 is tensor(1.0184)\n",
            "train_5 loss at epoch number 10 is tensor(1.0162)\n",
            "train_5 loss at epoch number 11 is tensor(1.0146)\n",
            "train_5 loss at epoch number 12 is tensor(1.0134)\n",
            "train_5 loss at epoch number 13 is tensor(1.0126)\n",
            "train_5 loss at epoch number 14 is tensor(1.0117)\n",
            "train_5 loss at epoch number 15 is tensor(1.0112)\n",
            "train_5 loss at epoch number 16 is tensor(1.0106)\n",
            "train_5 loss at epoch number 17 is tensor(1.0101)\n",
            "train_5 loss at epoch number 18 is tensor(1.0096)\n",
            "train_5 loss at epoch number 19 is tensor(1.0094)\n",
            "train_5 loss at epoch number 20 is tensor(1.0090)\n",
            "train_5 loss at epoch number 21 is tensor(1.0090)\n",
            "train_5 loss at epoch number 22 is tensor(1.0085)\n",
            "train_5 loss at epoch number 23 is tensor(1.0082)\n",
            "train_5 loss at epoch number 24 is tensor(1.0080)\n",
            "train_5 loss at epoch number 25 is tensor(1.0080)\n",
            "train_5 loss at epoch number 26 is tensor(1.0082)\n",
            "train_5 loss at epoch number 27 is tensor(1.0081)\n",
            "train_5 loss at epoch number 28 is tensor(1.0077)\n",
            "train_5 loss at epoch number 29 is tensor(1.0076)\n",
            "train_5 loss at epoch number 30 is tensor(1.0066)\n",
            "train_5 loss at epoch number 31 is tensor(1.0059)\n",
            "train_5 loss at epoch number 32 is tensor(1.0042)\n",
            "train_5 loss at epoch number 33 is tensor(1.0043)\n",
            "train_5 loss at epoch number 34 is tensor(1.0026)\n",
            "train_5 loss at epoch number 35 is tensor(1.0021)\n",
            "train_5 loss at epoch number 36 is tensor(0.9993)\n",
            "train_5 loss at epoch number 37 is tensor(0.9993)\n",
            "train_5 loss at epoch number 38 is tensor(0.9968)\n",
            "train_5 loss at epoch number 39 is tensor(0.9967)\n",
            "train_5 loss at epoch number 40 is tensor(0.9947)\n",
            "train_5 loss at epoch number 41 is tensor(0.9938)\n",
            "train_5 loss at epoch number 42 is tensor(0.9914)\n",
            "train_5 loss at epoch number 43 is tensor(0.9919)\n",
            "train_5 loss at epoch number 44 is tensor(0.9889)\n",
            "train_5 loss at epoch number 45 is tensor(0.9893)\n",
            "train_5 loss at epoch number 46 is tensor(0.9869)\n",
            "train_5 loss at epoch number 47 is tensor(0.9864)\n",
            "train_5 loss at epoch number 48 is tensor(0.9847)\n",
            "train_5 loss at epoch number 49 is tensor(0.9842)\n",
            "train_5 loss at epoch number 50 is tensor(0.9823)\n",
            "train_5 loss at epoch number 51 is tensor(0.9815)\n",
            "train_5 loss at epoch number 52 is tensor(0.9797)\n",
            "train_5 loss at epoch number 53 is tensor(0.9792)\n",
            "train_5 loss at epoch number 54 is tensor(0.9775)\n",
            "train_5 loss at epoch number 55 is tensor(0.9769)\n",
            "train_5 loss at epoch number 56 is tensor(0.9751)\n",
            "train_5 loss at epoch number 57 is tensor(0.9752)\n",
            "train_5 loss at epoch number 58 is tensor(0.9725)\n",
            "train_5 loss at epoch number 59 is tensor(0.9731)\n",
            "train_5 loss at epoch number 60 is tensor(0.9703)\n",
            "train_5 loss at epoch number 61 is tensor(0.9718)\n",
            "train_5 loss at epoch number 62 is tensor(0.9687)\n",
            "train_5 loss at epoch number 63 is tensor(0.9696)\n",
            "train_5 loss at epoch number 64 is tensor(0.9667)\n",
            "train_5 loss at epoch number 65 is tensor(0.9678)\n",
            "train_5 loss at epoch number 66 is tensor(0.9647)\n",
            "train_5 loss at epoch number 67 is tensor(0.9654)\n",
            "train_5 loss at epoch number 68 is tensor(0.9626)\n",
            "train_5 loss at epoch number 69 is tensor(0.9640)\n",
            "train_5 loss at epoch number 70 is tensor(0.9611)\n",
            "train_5 loss at epoch number 71 is tensor(0.9621)\n",
            "train_5 loss at epoch number 72 is tensor(0.9589)\n",
            "train_5 loss at epoch number 73 is tensor(0.9604)\n",
            "train_5 loss at epoch number 74 is tensor(0.9575)\n",
            "train_5 loss at epoch number 75 is tensor(0.9585)\n",
            "train_5 loss at epoch number 76 is tensor(0.9554)\n",
            "train_5 loss at epoch number 77 is tensor(0.9565)\n",
            "train_5 loss at epoch number 78 is tensor(0.9540)\n",
            "train_5 loss at epoch number 79 is tensor(0.9544)\n",
            "train_5 loss at epoch number 80 is tensor(0.9522)\n",
            "train_5 loss at epoch number 81 is tensor(0.9528)\n",
            "train_5 loss at epoch number 82 is tensor(0.9500)\n",
            "train_5 loss at epoch number 83 is tensor(0.9507)\n",
            "train_5 loss at epoch number 84 is tensor(0.9485)\n",
            "train_5 loss at epoch number 85 is tensor(0.9492)\n",
            "train_5 loss at epoch number 86 is tensor(0.9463)\n",
            "train_5 loss at epoch number 87 is tensor(0.9472)\n",
            "train_5 loss at epoch number 88 is tensor(0.9445)\n",
            "train_5 loss at epoch number 89 is tensor(0.9454)\n",
            "train_5 loss at epoch number 90 is tensor(0.9430)\n",
            "train_5 loss at epoch number 91 is tensor(0.9436)\n",
            "train_5 loss at epoch number 92 is tensor(0.9409)\n",
            "train_5 loss at epoch number 93 is tensor(0.9413)\n",
            "train_5 loss at epoch number 94 is tensor(0.9395)\n",
            "train_5 loss at epoch number 95 is tensor(0.9403)\n",
            "train_5 loss at epoch number 96 is tensor(0.9377)\n",
            "train_5 loss at epoch number 97 is tensor(0.9389)\n",
            "train_5 loss at epoch number 98 is tensor(0.9365)\n",
            "train_5 loss at epoch number 99 is tensor(0.9378)\n",
            "train_5 loss at epoch number 100 is tensor(0.9356)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psNFwRaLIm6-"
      },
      "source": [
        "#Testing the autoencoder : part 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40pIG_39aWWs",
        "outputId": "32799c60-0208-4adf-dfe9-52bff3fce5da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "test_loss5 ,s5  = 0 , 0.\n",
        " \n",
        "for ui in range(user_count):\n",
        "  input_info = Variable(training_set_5[ui]).unsqueeze(0)\n",
        "  target_info = Variable(test_set_5[ui]).unsqueeze(0)\n",
        "  if torch.sum(target_info.data>0)> 0:\n",
        "    output_info =archi(input_info)\n",
        "    target_info.require_grad= False\n",
        "    output_info[target_info== 0] = 0\n",
        "    l= criterion(output_info, target_info)\n",
        "    adj_cons =movies_count/float(torch.sum(target_info.data > 0) + 1e-10)\n",
        "    test_loss5 += np.sqrt(l.data*adj_cons)\n",
        "    s5+= 1.\n",
        "print('test_5 loss: '+str(test_loss5/s5))\n",
        "print()\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_5 loss: tensor(0.9841)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EPkt5FBacx_"
      },
      "source": [
        "#Calculating total error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5Lq4xwpagtv",
        "outputId": "44cfa8a1-5bfb-4fd1-9d02-49267a076b14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "total_error = ((test_loss1)/s1) + ((test_loss2)/s2) + ((test_loss3)/s3) + ((test_loss4)/s4) + ((test_loss5)/s5)\n",
        "total_error /= 5.0\n",
        "print(\"Total average Loss after 5-fold cross Validation : \" + str(total_error))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total average Loss after 5-fold cross Validation : tensor(0.9846)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}